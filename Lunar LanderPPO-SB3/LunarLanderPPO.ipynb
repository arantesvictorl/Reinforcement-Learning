{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LunarLanderPPO",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Instalação\n",
        "\n"
      ],
      "metadata": {
        "id": "6v0DOILuPqLV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1DKOVa8O-wx"
      },
      "outputs": [],
      "source": [
        "!pip3 install box2d-py\n",
        "!pip3 install gym[Box_2D]\n",
        "!pip install stable_baselines3\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Display Virtual para gravar vídeos\n",
        "from pyvirtualdisplay import Display\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ],
      "metadata": {
        "id": "lOaRcDjykZk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importações"
      ],
      "metadata": {
        "id": "vVXlpF8_PwHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ambientes\n",
        "import gym\n",
        "# Recursos RL\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "# from stable_baselines3.common.logger import configure\n",
        "# Recursos de Video\n",
        "from gym.wrappers import RecordVideo"
      ],
      "metadata": {
        "id": "CpGn-SwHPd7S"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento"
      ],
      "metadata": {
        "id": "uqWvJqyTP43J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação do Ambiente\n",
        "\n",
        "`make_vec_env `  permite treinar um agente em vários ambientes em paralelo. Como a maioria dos algoritmos de aprendizado por reforço são muito famintos por \"experiência\", ter vários ambientes rodando em paralelo faz com que o agente aprenda rapidamente como se comportar."
      ],
      "metadata": {
        "id": "G1mqogS-QGpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ambiente = make_vec_env('LunarLander-v2', 4)"
      ],
      "metadata": {
        "id": "3H_me3DzP3GD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criação do Agente"
      ],
      "metadata": {
        "id": "8KzseDWiS_L6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui você encontra a descrição dos Parâmetros da PPO:<br>\n",
        "<https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html>"
      ],
      "metadata": {
        "id": "ComrRhQVdq6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciar o Agente\n",
        "# agente = PPO(\"MlpPolicy\", ambiente, verbose=1)\n",
        "agente = PPO(\n",
        "    policy = 'MlpPolicy',\n",
        "    env = ambiente,\n",
        "    n_steps = 1024,\n",
        "    batch_size = 64,\n",
        "    n_epochs = 4,\n",
        "    gamma = 0.999,\n",
        "    gae_lambda = 0.98,\n",
        "    ent_coef = 0.01,\n",
        "    verbose=1,\n",
        "    tensorboard_log=\"LogtensorPPO\")\n",
        "# Treinar o Agente\n",
        "agente.learn(total_timesteps=5000000, tb_log_name=\"PrimeiroTreino\")\n",
        "# Salvar o Agente\n",
        "nomeAgente = \"agenteLunarLander\"\n",
        "agente.save(nomeAgente)"
      ],
      "metadata": {
        "id": "vXwFspzUSJfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliação do Agente"
      ],
      "metadata": {
        "id": "FK6Va1BHT2pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ambienteAva = gym.make(\"LunarLander-v2\")\n",
        "media_recompensas, desvio_padrao_recompensas = evaluate_policy(agente, ambienteAva, n_eval_episodes=10, deterministic=True)\n",
        "print(f\"Média de Recompensas: {media_recompensas:.2f} Desvio Padrão de Recompensas: {desvio_padrao_recompensas:.2f}\")\n"
      ],
      "metadata": {
        "id": "hB4EP2etUI_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gravar um vídeo do Agente Treinado"
      ],
      "metadata": {
        "id": "aNQitJp7VxVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ambienteAva = gym.make(\"LunarLander-v2\")\n",
        "ambienteAva = RecordVideo(ambienteAva, './video' )"
      ],
      "metadata": {
        "id": "XbqjHWHEk0m3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descomente essa linha se quiser gravar um vídeo de um modelo salvo\n",
        "# agente = PPO.load(\"/content/agenteLunarLander.zip\", ambienteAva)\n"
      ],
      "metadata": {
        "id": "HIr1t_PhkouO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs = ambienteAva.reset()\n",
        "concluido = False\n",
        "while not concluido:\n",
        "  acao, _estado = agente.predict(obs)\n",
        "  obs, recompensa, concluido, info = ambienteAva.step(acao)\n"
      ],
      "metadata": {
        "id": "52DCk4LTV9J5"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}